HƯỚNG DẪN BÁO CÁO TRIỂN KHAI ELK STACK TRÊN DOCKER SWARM
====================================================

MỤC LỤC:
1. Logstash chạy trên swarm với 2 replicas
2. Test log của logstash đọc logs từ 4 services: rng,hasher,worker,webui
3. Logstash xử lý lấy dữ liệu log theo filter với các thông tin quan trọng
4. Elasticsearch chạy trên swarm
5. Truy vấn dữ liệu trong elasticsearch
6. Kibana chạy trên swarm
7. Kibana kết nối lấy dữ liệu thành công từ ElasticSearch
8. Thao tác Kibana tìm kiếm logs, trực quan, phân tích dữ liệu logs

====================================================

1. LOGSTASH CHẠY TRÊN SWARM VỚI 2 REPLICAS
-------------------------------------------

Các bước thực hiện:
1.1. Dùng lệnh `docker service ls` để hiển thị Logstash chạy với 2 replicas
    ```
    docker service ls | grep logstash
    ```

1.2. Dùng lệnh `docker service ps elk_logstash` để xem chi tiết các container Logstash đang chạy trên các node
    ```
    docker service ps elk_logstash
    ```

1.3. Copy phần cấu hình trong file docker-stack.yml liên quan đến Logstash vào báo cáo, đặc biệt là phần:
    ```yaml
    logstash:
      ...
      deploy:
        replicas: 2
    ```

1.4. Kiểm tra log của service Logstash để đảm bảo nó hoạt động bình thường
    ```
    docker service logs elk_logstash
    ```

2. TEST LOG CỦA LOGSTASH ĐỌC LOGS TỪ 4 SERVICES
----------------------------------------------

Các bước thực hiện:
2.1. Đảm bảo 4 services (rng, hasher, worker, webui) đang chạy:
    ```
    docker service ls | grep -E "rng|hasher|worker|webui"
    ```

2.2. Tạo logs ở các service test:
    - Truy cập webui qua trình duyệt tại địa chỉ http://<IP_VPS0>:5000
    - Thực hiện một số thao tác để tạo logs
    - Hoặc tạo logs thủ công bằng cách:
      ```
      docker service scale elk_rng=0 elk_rng=2
      docker service scale elk_hasher=0 elk_hasher=2
      ```

2.3. Kiểm tra xem Logstash có nhận được logs từ các service:
    ```
    docker service logs elk_logstash | grep -E "rng|hasher|worker|webui"
    ```

2.4. Kiểm tra output từ Logstash hiển thị các log được nhận từ mỗi service

3. LOGSTASH XỬ LÝ LẤY DỮ LIỆU LOG THEO FILTER
--------------------------------------------

Các bước thực hiện:
3.1. Copy và giải thích phần cấu hình filter trong file logstash.conf:
    - Phần filter phân loại logs theo từng service
    - Phần grok pattern để trích xuất timestamp, log level và log message
    - Phần filter cho logs ERROR/FATAL
    - Phần filter cho các từ khóa quan trọng (exception, error, ...)

3.2. Kiểm tra log của Logstash với codec rubydebug để xem dữ liệu được xử lý:
    ```
    docker service logs elk_logstash | grep -A 20 "rubydebug"
    ```

3.3. Truy cập vào một container Logstash để kiểm tra cấu hình:
    ```
    docker ps | grep logstash
    docker exec -it <container_id> bash
    cat /usr/share/logstash/pipeline/logstash.conf
    ```

3.4. Giải thích các tag được thêm vào mỗi loại log:
    - Tags: rng_service, hasher_service, worker_service, webui_service
    - Tags: error_log (cho logs ERROR/FATAL)
    - Tags: important (cho logs có từ khóa quan trọng)

4. ELASTICSEARCH CHẠY TRÊN SWARM
-------------------------------

Các bước thực hiện:
4.1. Dùng lệnh `docker service ls | grep elasticsearch` để xác nhận Elasticsearch đang chạy

4.2. Kiểm tra trạng thái Elasticsearch cluster:
    ```
    curl -X GET "http://<IP_VPS0>:9200/_cluster/health?pretty"
    ```

4.3. Kiểm tra response, đảm bảo status là "green" hoặc "yellow"

4.4. Kiểm tra các nodes trong cluster:
    ```
    curl -X GET "http://<IP_VPS0>:9200/_cat/nodes?v"
    ```

4.5. Kiểm tra thông tin phiên bản Elasticsearch:
    ```
    curl -X GET "http://<IP_VPS0>:9200"
    ```

5. TRUY VẤN DỮ LIỆU TRONG ELASTICSEARCH
-------------------------------------

Các bước thực hiện:
5.1. Liệt kê tất cả các index trong Elasticsearch:
    ```
    curl -X GET "http://<IP_VPS0>:9200/_cat/indices?v"
    ```

5.2. Dùng, tìm các index bắt đầu bằng "logs-"

5.3. Thực hiện các truy vấn sau:

    a. Tìm logs từ service rng:
    ```
    curl -X GET "http://<IP_VPS0>:9200/logs-rng-*/_search?pretty" -H 'Content-Type: application/json' -d'
    {
      "query": {
        "match_all": {}
      },
      "size": 10,
      "sort": [
        {
          "@timestamp": {
            "order": "desc"
          }
        }
      ]
    }'
    ```

    b. Tìm logs cấp độ ERROR:
    ```
    curl -X GET "http://<IP_VPS0>:9200/logs-*/_search?pretty" -H 'Content-Type: application/json' -d'
    {
      "query": {
        "match": {
          "tags": "error_log"
        }
      },
      "size": 10,
      "sort": [
        {
          "@timestamp": {
            "order": "desc"
          }
        }
      ]
    }'
    ```

    c. Tìm logs có từ khóa "exception" hoặc "error":
    ```
    curl -X GET "http://<IP_VPS0>:9200/logs-*/_search?pretty" -H 'Content-Type: application/json' -d'
    {
      "query": {
        "query_string": {
          "query": "log_message:exception OR log_message:error",
          "default_field": "log_message"
        }
      },
      "size": 10
    }'
    ```

    d. Thống kê số lượng log theo service:
    ```
    curl -X GET "http://<IP_VPS0>:9200/logs-*/_search?pretty" -H 'Content-Type: application/json' -d'
    {
      "size": 0,
      "aggs": {
        "service_count": {
          "terms": {
            "field": "service_name.keyword",
            "size": 10
          }
        }
      }
    }'
    ```

6. KIBANA CHẠY TRÊN SWARM
-----------------------

Các bước thực hiện:
6.1. Dùng lệnh `docker service ls | grep kibana` để xác nhận Kibana đang chạy

6.2. Kiểm tra log của service Kibana:
    ```
    docker service logs elk_kibana
    ```

6.3. Kiểm tra giao diện Kibana khi truy cập vào http://<IP_VPS0>:5601

6.4. Kiểm tra phần trạng thái của Kibana ở mục Management > Stack Monitoring

7. KIBANA KẾT NỐI LẤY DỮ LIỆU THÀNH CÔNG TỪ ELASTICSEARCH
-------------------------------------------------------

Các bước thực hiện:
7.1. Tạo Index Pattern trong Kibana:
    - Vào Stack Management > Index Patterns > Create index pattern
    - Nhập "logs-*" làm pattern name
    - Chọn @timestamp làm Time field
    - Kiểm tra quá trình tạo và kết quả cuối cùng

7.2. Kiểm tra kết nối giữa Kibana và Elasticsearch:
    - Vào Dev Tools trong Kibana
    - Chạy lệnh: GET _cluster/health và Dùng
    - Chạy lệnh: GET _cat/indices và Dùng

7.3. Hiển thị các fields có sẵn trong index pattern logs-*

8. THAO TÁC KIBANA TÌM KIẾM LOGS, TRỰC QUAN, PHÂN TÍCH DỮ LIỆU LOGS
-----------------------------------------------------------------

Các bước thực hiện:
8.1. Tìm kiếm logs:
    - Vào Discover
    - Chọn index pattern logs-*
    - Thực hiện các tìm kiếm sau và Dùng:
        * service_name: "rng"
        * log_level: "ERROR" hoặc tags: "error_log"
        * message: *exception* hoặc message: *error*

8.2. Tạo Visualization:
    a. Tạo biểu đồ line hiển thị logs theo thời gian:
        - Vào Visualize > Create visualization > Line
        - Thiết lập:
            * Metrics: Y-axis - Count
            * Buckets: X-axis - Date Histogram trên trường @timestamp
        - Dùng

    b. Tạo biểu đồ pie hiển thị tỷ lệ logs theo service:
        - Vào Visualize > Create visualization > Pie
        - Thiết lập:
            * Metrics: Count
            * Buckets: Split slices - Terms trên trường service_name.keyword
        - Dùng

    c. Tạo data table hiển thị logs error gần đây:
        - Vào Visualize > Create visualization > Data Table
        - Thêm filter: tags: "error_log"
        - Thiết lập:
            * Metrics: Count
            * Buckets: Split rows - Terms trên trường service_name.keyword
            * Buckets: Split rows - Terms trên trường log_message.keyword
        - Dùng

8.3. Tạo Dashboard:
    - Vào Dashboard > Create dashboard
    - Thêm các visualization đã tạo ở bước trước
    - Sắp xếp các visualization một cách hợp lý
    - Thêm bộ lọc thời gian (VD: Last 24 hours)
    - Dùng dashboard
    - Lưu dashboard với tên "ELK Services Monitoring"

8.4. Cấu hình cảnh báo (nếu có):
    - Vào Stack Management > Rules and Connectors
    - Tạo rule cảnh báo khi có quá nhiều logs ERROR trong một khoảng thời gian
    - Check cấu hình

====================================================
